import os

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import Chroma
from langchain_openai import OpenAIEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_ollama import OllamaEmbeddings

from utils import get_config


def run_ingestion():
    config = get_config()
    print("ğŸ“‚ KROK 1: Szukam plikÃ³w w folderze data...")

    documents = []
    # Upewnijmy siÄ™, Å¼e Å›cieÅ¼ka jest absolutna dla Windowsa
    data_path = os.path.abspath(config["data_path"])

    files = [f for f in os.listdir(data_path) if f.endswith(".pdf")]
    print(f"ğŸ“„ Znaleziono pliki: {files}")

    for file in files:
        print(f"ğŸ“– ÅadujÄ™ plik: {file}...")
        loader = PyPDFLoader(os.path.join(data_path, file))
        documents.extend(loader.load())

    if not documents:
        print("âŒ Folder data/ jest pusty lub nie ma w nim PDFÃ³w!")
        return

    print(f"âœ‚ï¸ KROK 2: DzielÄ™ tekst na fragmenty (Chunking)...")
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000, chunk_overlap=150, add_start_index=True
    )
    chunks = text_splitter.split_documents(documents)
    print(f"âœ… Podzielono na {len(chunks)} fragmentÃ³w.")

    print(f"ğŸ§  KROK 3: WysyÅ‚am do Ollamy (to moÅ¼e potrwaÄ‡)...")
    try:
        vectorstore = Chroma.from_documents(
            documents=chunks,
            embedding = OllamaEmbeddings(model="nomic-embed-text"),
            persist_directory=config["chroma_path"],
        )
        print(f"ğŸš€ SUKCES! Przetworzono {len(chunks)} fragmentÃ³w.")
    except Exception as e:
        print(f"âŒ BÅÄ„D wektoryzacji: {e}")


if __name__ == "__main__":
    run_ingestion()
